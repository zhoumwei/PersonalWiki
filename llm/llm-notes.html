<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.20" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const useChoice = localStorage.getItem('vuepress-color-scheme')
      const systemStatus =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (useChoice === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (useChoice === 'dark' || systemStatus) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>大模型(LLM)学习笔记 | PersonalWiki</title><meta name="description" content="My PersonalWiki Site">
    <link rel="preload" href="/assets/style-QXEKf4Y2.css" as="style"><link rel="stylesheet" href="/assets/style-QXEKf4Y2.css">
    <link rel="modulepreload" href="/assets/app-BvwJZ6kh.js"><link rel="modulepreload" href="/assets/llm-notes.html-QVyBkdng.js">
    <link rel="prefetch" href="/assets/index.html-CbTDEAts.js" as="script"><link rel="prefetch" href="/assets/get-started.html-CjD3fAAo.js" as="script"><link rel="prefetch" href="/assets/index.html-DSrufwo5.js" as="script"><link rel="prefetch" href="/assets/flink-notes.html-BpXJ8u78.js" as="script"><link rel="prefetch" href="/assets/hadoop-notes.html-C4UlBBUF.js" as="script"><link rel="prefetch" href="/assets/hbase-notes.html-CTid9EA9.js" as="script"><link rel="prefetch" href="/assets/hive-notes.html-BCTrtLqN.js" as="script"><link rel="prefetch" href="/assets/spark-notes.html-DjBDa7xt.js" as="script"><link rel="prefetch" href="/assets/time-series-data.html-Cpf5Qxjz.js" as="script"><link rel="prefetch" href="/assets/index.html-BWfX9Mq_.js" as="script"><link rel="prefetch" href="/assets/anomaly-detection.html-Bg2YjLXz.js" as="script"><link rel="prefetch" href="/assets/solution-overview.html-CetPEQ_x.js" as="script"><link rel="prefetch" href="/assets/index.html-D_AXRVv7.js" as="script"><link rel="prefetch" href="/assets/redis-notes.html-BjkbebZR.js" as="script"><link rel="prefetch" href="/assets/index.html-Df8gWSBm.js" as="script"><link rel="prefetch" href="/assets/mysql-notes.html-s5dCwXKf.js" as="script"><link rel="prefetch" href="/assets/index.html-eSWmtd0l.js" as="script"><link rel="prefetch" href="/assets/css-interview.html-DluBQhYO.js" as="script"><link rel="prefetch" href="/assets/html-interview.html-Cyy3AGVn.js" as="script"><link rel="prefetch" href="/assets/javascript-interview.html-CG7UI4-t.js" as="script"><link rel="prefetch" href="/assets/layout-methods.html-pL0_j4Ng.js" as="script"><link rel="prefetch" href="/assets/react-interview.html-CIa2Sn63.js" as="script"><link rel="prefetch" href="/assets/vue-interview.html-K5pEBcjG.js" as="script"><link rel="prefetch" href="/assets/index.html-TRTe0zxa.js" as="script"><link rel="prefetch" href="/assets/android-interview.html-ada45Htj.js" as="script"><link rel="prefetch" href="/assets/java-basic-interview.html-DjUXvpr3.js" as="script"><link rel="prefetch" href="/assets/jmm-notes.html-MDd7Ko4J.js" as="script"><link rel="prefetch" href="/assets/jvm-notes.html-DLuG0MRh.js" as="script"><link rel="prefetch" href="/assets/multithreading-interview.html-D5DrrSe3.js" as="script"><link rel="prefetch" href="/assets/multithreading-notes.html-DfVio_Fi.js" as="script"><link rel="prefetch" href="/assets/index.html-BnS01Ekr.js" as="script"><link rel="prefetch" href="/assets/fine-tuning.html-CjBB1ax_.js" as="script"><link rel="prefetch" href="/assets/prompt-engineering.html-DNhy9bB9.js" as="script"><link rel="prefetch" href="/assets/training-optimization.html-xAtwji5x.js" as="script"><link rel="prefetch" href="/assets/transformer-notes.html-CipMRP38.js" as="script"><link rel="prefetch" href="/assets/index.html-Cw2F1Agy.js" as="script"><link rel="prefetch" href="/assets/machine-learning.html-B-iGr0DC.js" as="script"><link rel="prefetch" href="/assets/index.html-Dg7P-8V_.js" as="script"><link rel="prefetch" href="/assets/kafka-notes.html-BetCbVDF.js" as="script"><link rel="prefetch" href="/assets/index.html-BKcXiGDb.js" as="script"><link rel="prefetch" href="/assets/nodejs-interview.html-B9dtC6T3.js" as="script"><link rel="prefetch" href="/assets/archive1.html-CU_-lS65.js" as="script"><link rel="prefetch" href="/assets/archive2.html-Dnyy_0hM.js" as="script"><link rel="prefetch" href="/assets/article1.html-An39HM8J.js" as="script"><link rel="prefetch" href="/assets/article10.html-B4wvKqrh.js" as="script"><link rel="prefetch" href="/assets/article11.html-BwLv2ZIG.js" as="script"><link rel="prefetch" href="/assets/article12.html-ey-3Numx.js" as="script"><link rel="prefetch" href="/assets/article2.html-B6IJZCZx.js" as="script"><link rel="prefetch" href="/assets/article3.html-WQYkFWda.js" as="script"><link rel="prefetch" href="/assets/article4.html-3reFRa1Y.js" as="script"><link rel="prefetch" href="/assets/article5.html-BAgHH7zk.js" as="script"><link rel="prefetch" href="/assets/article6.html-Ci6HTPLI.js" as="script"><link rel="prefetch" href="/assets/article7.html-CGCzq-HI.js" as="script"><link rel="prefetch" href="/assets/article8.html-DAf_qtAn.js" as="script"><link rel="prefetch" href="/assets/article9.html-BJ_PclXO.js" as="script"><link rel="prefetch" href="/assets/sticky.html-DzYDdEpa.js" as="script"><link rel="prefetch" href="/assets/sticky2.html-DxwKeFc6.js" as="script"><link rel="prefetch" href="/assets/index.html-SKjZhXJG.js" as="script"><link rel="prefetch" href="/assets/brew-tutorial.html-HINWWcf0.js" as="script"><link rel="prefetch" href="/assets/linux-notes.html-Bs6UdVSt.js" as="script"><link rel="prefetch" href="/assets/nvm-tutorial.html-CQ4cnbiJ.js" as="script"><link rel="prefetch" href="/assets/tencent-cloud-config.html-BAq6h3ta.js" as="script"><link rel="prefetch" href="/assets/404.html-Bocm2NQp.js" as="script"><link rel="prefetch" href="/assets/index.html-D7ucGqBj.js" as="script"><link rel="prefetch" href="/assets/index.html-Kt4soQse.js" as="script"><link rel="prefetch" href="/assets/index.html-DP6wngEx.js" as="script"><link rel="prefetch" href="/assets/index.html-CyRJUuAN.js" as="script"><link rel="prefetch" href="/assets/index.html-CSYpLAM6.js" as="script"><link rel="prefetch" href="/assets/index.html-DkIn-eRi.js" as="script"><link rel="prefetch" href="/assets/index.html-CFDck-Pn.js" as="script"><link rel="prefetch" href="/assets/index.html-BCj8RVxP.js" as="script"><link rel="prefetch" href="/assets/index.html-C6DXimEX.js" as="script"><link rel="prefetch" href="/assets/index.html-TPQAqjy9.js" as="script"><link rel="prefetch" href="/assets/index.html-Bdmct_gh.js" as="script"><link rel="prefetch" href="/assets/index.html-fHklgrv9.js" as="script"><link rel="prefetch" href="/assets/index.html-BKdawjmQ.js" as="script"><link rel="prefetch" href="/assets/index.html-Dam71-Kz.js" as="script"><link rel="prefetch" href="/assets/index.html-C4b-Z5oU.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="/logo.svg" alt="PersonalWiki"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">PersonalWiki</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/article/" aria-label="Article"><!--[--><!--[--><!--]--><!--]-->Article<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/aiops/" aria-label="AIOps"><!--[--><!--[--><!--]--><!--]-->AIOps<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/bigdata/" aria-label="BigData"><!--[--><!--[--><!--]--><!--]-->BigData<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/cache/" aria-label="Cache"><!--[--><!--[--><!--]--><!--]-->Cache<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/database/" aria-label="Database"><!--[--><!--[--><!--]--><!--]-->Database<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/java/" aria-label="Java"><!--[--><!--[--><!--]--><!--]-->Java<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/llm/" aria-label="LLM"><!--[--><!--[--><!--]--><!--]-->LLM<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/ml/" aria-label="ML"><!--[--><!--[--><!--]--><!--]-->ML<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/mq/" aria-label="MQ"><!--[--><!--[--><!--]--><!--]-->MQ<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/nodejs/" aria-label="Node.js"><!--[--><!--[--><!--]--><!--]-->Node.js<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/system/" aria-label="System"><!--[--><!--[--><!--]--><!--]-->System<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/category/" aria-label="Category"><!--[--><!--[--><!--]--><!--]-->Category<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tag/" aria-label="Tag"><!--[--><!--[--><!--]--><!--]-->Tag<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/timeline/" aria-label="Timeline"><!--[--><!--[--><!--]--><!--]-->Timeline<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/article/" aria-label="Article"><!--[--><!--[--><!--]--><!--]-->Article<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/aiops/" aria-label="AIOps"><!--[--><!--[--><!--]--><!--]-->AIOps<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/bigdata/" aria-label="BigData"><!--[--><!--[--><!--]--><!--]-->BigData<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/cache/" aria-label="Cache"><!--[--><!--[--><!--]--><!--]-->Cache<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/database/" aria-label="Database"><!--[--><!--[--><!--]--><!--]-->Database<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/java/" aria-label="Java"><!--[--><!--[--><!--]--><!--]-->Java<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/llm/" aria-label="LLM"><!--[--><!--[--><!--]--><!--]-->LLM<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/ml/" aria-label="ML"><!--[--><!--[--><!--]--><!--]-->ML<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/mq/" aria-label="MQ"><!--[--><!--[--><!--]--><!--]-->MQ<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/nodejs/" aria-label="Node.js"><!--[--><!--[--><!--]--><!--]-->Node.js<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/system/" aria-label="System"><!--[--><!--[--><!--]--><!--]-->System<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/category/" aria-label="Category"><!--[--><!--[--><!--]--><!--]-->Category<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/tag/" aria-label="Tag"><!--[--><!--[--><!--]--><!--]-->Tag<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/timeline/" aria-label="Timeline"><!--[--><!--[--><!--]--><!--]-->Timeline<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active">大语言模型 <!----></p><ul class="vp-sidebar-children" style=""><!--[--><li><a class="route-link route-link-active auto-link vp-sidebar-item" href="/llm/" aria-label="大语言模型(LLM)学习笔记"><!--[--><!--[--><!--]--><!--]-->大语言模型(LLM)学习笔记<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/llm/llm-notes.html" aria-label="大模型(LLM)学习笔记"><!--[--><!--[--><!--]--><!--]-->大模型(LLM)学习笔记<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/transformer-notes.html" aria-label="Transformer架构学习笔记"><!--[--><!--[--><!--]--><!--]-->Transformer架构学习笔记<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/prompt-engineering.html" aria-label="提示工程(Prompt Engineering)学习笔记"><!--[--><!--[--><!--]--><!--]-->提示工程(Prompt Engineering)学习笔记<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/fine-tuning.html" aria-label="大模型微调(Fine-tuning)学习笔记"><!--[--><!--[--><!--]--><!--]-->大模型微调(Fine-tuning)学习笔记<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/llm/training-optimization.html" aria-label="大模型训练与优化学习笔记"><!--[--><!--[--><!--]--><!--]-->大模型训练与优化学习笔记<!--[--><!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div vp-content><!--[--><!--]--><div><h1 id="大模型-llm-学习笔记" tabindex="-1"><a class="header-anchor" href="#大模型-llm-学习笔记"><span>大模型(LLM)学习笔记</span></a></h1><h2 id="什么是大模型" tabindex="-1"><a class="header-anchor" href="#什么是大模型"><span>什么是大模型</span></a></h2><p>大模型（Large Language Model，LLM）是一类具有超大规模参数量的深度学习模型，通常包含数十亿甚至数千亿个参数。它们通过在大量文本数据上进行训练，能够理解和生成人类语言，执行各种自然语言处理任务。</p><h2 id="大模型发展历史" tabindex="-1"><a class="header-anchor" href="#大模型发展历史"><span>大模型发展历史</span></a></h2><h3 id="_1-早期语言模型" tabindex="-1"><a class="header-anchor" href="#_1-早期语言模型"><span>1. 早期语言模型</span></a></h3><ul><li>N-gram模型：基于统计的语言模型</li><li>神经网络语言模型：使用神经网络进行语言建模</li></ul><h3 id="_2-预训练模型时代" tabindex="-1"><a class="header-anchor" href="#_2-预训练模型时代"><span>2. 预训练模型时代</span></a></h3><ul><li><strong>2018年：BERT</strong> - Google提出的双向Transformer模型，开启了预训练+微调的新范式</li><li><strong>2019年：GPT-2</strong> - OpenAI发布的第二代GPT模型，展示了强大的文本生成能力</li><li><strong>2020年：GPT-3</strong> - OpenAI发布的第一代真正意义上的大模型，拥有1750亿参数</li></ul><h3 id="_3-大模型爆发期" tabindex="-1"><a class="header-anchor" href="#_3-大模型爆发期"><span>3. 大模型爆发期</span></a></h3><ul><li><strong>2022年：ChatGPT</strong> - OpenAI基于GPT-3.5推出的对话式AI，引发全球关注</li><li><strong>2023年：GPT-4</strong> - 更强大的多模态大模型</li><li><strong>Claude、PaLM、LLaMA</strong> 等一系列大模型相继问世</li></ul><h2 id="大模型核心技术" tabindex="-1"><a class="header-anchor" href="#大模型核心技术"><span>大模型核心技术</span></a></h2><h3 id="_1-transformer架构" tabindex="-1"><a class="header-anchor" href="#_1-transformer架构"><span>1. Transformer架构</span></a></h3><ul><li><strong>自注意力机制</strong>：允许模型在处理序列时关注不同位置的信息</li><li><strong>编码器-解码器结构</strong>：处理输入和输出序列</li><li><strong>位置编码</strong>：为模型提供序列顺序信息</li></ul><h3 id="_2-预训练与微调" tabindex="-1"><a class="header-anchor" href="#_2-预训练与微调"><span>2. 预训练与微调</span></a></h3><ul><li><strong>预训练</strong>：在大规模语料上进行无监督学习</li><li><strong>微调</strong>：在特定任务上进行有监督学习</li><li><strong>提示工程</strong>：通过设计合适的提示词引导模型输出</li></ul><h3 id="_3-扩展定律-scaling-law" tabindex="-1"><a class="header-anchor" href="#_3-扩展定律-scaling-law"><span>3. 扩展定律（Scaling Law）</span></a></h3><ul><li>模型性能与模型大小、数据集大小、计算量呈幂律关系</li><li>增大模型规模通常能带来性能提升</li></ul><h2 id="主流大模型介绍" tabindex="-1"><a class="header-anchor" href="#主流大模型介绍"><span>主流大模型介绍</span></a></h2><h3 id="_1-gpt系列-openai" tabindex="-1"><a class="header-anchor" href="#_1-gpt系列-openai"><span>1. GPT系列（OpenAI）</span></a></h3><ul><li><strong>GPT-3</strong>：1750亿参数，强大的文本生成能力</li><li><strong>GPT-3.5</strong>：ChatGPT的基础模型</li><li><strong>GPT-4</strong>：多模态模型，更强的理解和推理能力</li></ul><h3 id="_2-llama系列-meta" tabindex="-1"><a class="header-anchor" href="#_2-llama系列-meta"><span>2. LLaMA系列（Meta）</span></a></h3><ul><li><strong>LLaMA</strong>：开源大模型，参数量从7B到65B</li><li><strong>LLaMA 2</strong>：改进版，开放商业使用</li><li><strong>LLaMA 3</strong>：最新的版本，性能进一步提升</li></ul><h3 id="_3-其他知名模型" tabindex="-1"><a class="header-anchor" href="#_3-其他知名模型"><span>3. 其他知名模型</span></a></h3><ul><li><strong>PaLM</strong>（Google）：Pathways Language Model</li><li><strong>Claude</strong>（Anthropic）：注重安全和可控性</li><li><strong>通义千问</strong>（阿里）：中文效果优秀的大模型</li><li><strong>文心一言</strong>（百度）：百度推出的大模型</li></ul><h2 id="大模型关键技术" tabindex="-1"><a class="header-anchor" href="#大模型关键技术"><span>大模型关键技术</span></a></h2><h3 id="_1-微调技术" tabindex="-1"><a class="header-anchor" href="#_1-微调技术"><span>1. 微调技术</span></a></h3><ul><li><strong>全参数微调</strong>：更新所有模型参数</li><li><strong>LoRA</strong>（Low-Rank Adaptation）：低秩适应，只训练少量参数</li><li><strong>Adapter</strong>：插入小型神经网络模块</li><li><strong>Prompt Tuning</strong>：优化提示词向量</li></ul><h3 id="_2-模型压缩" tabindex="-1"><a class="header-anchor" href="#_2-模型压缩"><span>2. 模型压缩</span></a></h3><ul><li><strong>知识蒸馏</strong>：用大模型指导小模型训练</li><li><strong>模型剪枝</strong>：移除不重要的权重</li><li><strong>量化</strong>：降低数值精度减少存储需求</li></ul><h3 id="_3-推理加速" tabindex="-1"><a class="header-anchor" href="#_3-推理加速"><span>3. 推理加速</span></a></h3><ul><li><strong>KV Cache</strong>：缓存注意力机制中的键值对</li><li><strong>FlashAttention</strong>：优化注意力计算</li><li><strong>并行计算</strong>：模型并行和流水线并行</li></ul><h2 id="大模型应用领域" tabindex="-1"><a class="header-anchor" href="#大模型应用领域"><span>大模型应用领域</span></a></h2><h3 id="_1-自然语言处理" tabindex="-1"><a class="header-anchor" href="#_1-自然语言处理"><span>1. 自然语言处理</span></a></h3><ul><li>文本生成：文章写作、创意文案</li><li>问答系统：智能客服、知识问答</li><li>语言翻译：多语言互译</li><li>文本摘要：长文档摘要提取</li></ul><h3 id="_2-代码生成" tabindex="-1"><a class="header-anchor" href="#_2-代码生成"><span>2. 代码生成</span></a></h3><ul><li><strong>GitHub Copilot</strong>：代码自动补全</li><li><strong>CodeT5</strong>：代码理解与生成</li><li>智能编程助手</li></ul><h3 id="_3-多模态应用" tabindex="-1"><a class="header-anchor" href="#_3-多模态应用"><span>3. 多模态应用</span></a></h3><ul><li>图像描述生成</li><li>视频理解与生成</li><li>语音合成与识别</li></ul><h3 id="_4-专业领域应用" tabindex="-1"><a class="header-anchor" href="#_4-专业领域应用"><span>4. 专业领域应用</span></a></h3><ul><li>医疗诊断辅助</li><li>法律咨询</li><li>金融分析</li><li>教育辅导</li></ul><h2 id="大模型面临的挑战" tabindex="-1"><a class="header-anchor" href="#大模型面临的挑战"><span>大模型面临的挑战</span></a></h2><h3 id="_1-技术挑战" tabindex="-1"><a class="header-anchor" href="#_1-技术挑战"><span>1. 技术挑战</span></a></h3><ul><li><strong>幻觉问题</strong>：生成虚假或错误信息</li><li><strong>推理能力</strong>：复杂逻辑推理仍有不足</li><li><strong>可控性</strong>：难以精确控制输出内容</li><li><strong>可解释性</strong>：黑盒模型难以解释决策过程</li></ul><h3 id="_2-伦理与社会挑战" tabindex="-1"><a class="header-anchor" href="#_2-伦理与社会挑战"><span>2. 伦理与社会挑战</span></a></h3><ul><li><strong>偏见与歧视</strong>：可能延续训练数据中的偏见</li><li><strong>隐私泄露</strong>：可能记忆并泄露训练数据</li><li><strong>版权争议</strong>：训练数据的版权问题</li><li><strong>就业影响</strong>：对某些职业的冲击</li></ul><h3 id="_3-安全风险" tabindex="-1"><a class="header-anchor" href="#_3-安全风险"><span>3. 安全风险</span></a></h3><ul><li><strong>恶意使用</strong>：生成虚假信息、诈骗内容</li><li><strong>对抗攻击</strong>：通过特定输入误导模型</li><li><strong>越狱攻击</strong>：绕过安全限制</li></ul><h2 id="大模型评估方法" tabindex="-1"><a class="header-anchor" href="#大模型评估方法"><span>大模型评估方法</span></a></h2><h3 id="_1-基准测试" tabindex="-1"><a class="header-anchor" href="#_1-基准测试"><span>1. 基准测试</span></a></h3><ul><li><strong>GLUE/SuperGLUE</strong>：自然语言理解基准</li><li><strong>HELM</strong>：全面评估语言模型</li><li><strong>MT-Bench</strong>：多轮对话评估</li></ul><h3 id="_2-人工评估" tabindex="-1"><a class="header-anchor" href="#_2-人工评估"><span>2. 人工评估</span></a></h3><ul><li>评估生成内容的质量、相关性、安全性</li><li>比较不同模型的表现</li></ul><h3 id="_3-特定任务评估" tabindex="-1"><a class="header-anchor" href="#_3-特定任务评估"><span>3. 特定任务评估</span></a></h3><ul><li>根据具体应用场景设计评估指标</li></ul><h2 id="大模型发展趋势" tabindex="-1"><a class="header-anchor" href="#大模型发展趋势"><span>大模型发展趋势</span></a></h2><h3 id="_1-模型架构演进" tabindex="-1"><a class="header-anchor" href="#_1-模型架构演进"><span>1. 模型架构演进</span></a></h3><ul><li>更高效的注意力机制</li><li>混合专家模型（MoE）</li><li>稀疏激活机制</li></ul><h3 id="_2-多模态融合" tabindex="-1"><a class="header-anchor" href="#_2-多模态融合"><span>2. 多模态融合</span></a></h3><ul><li>文本、图像、音频、视频的深度融合</li><li>统一的多模态表示</li></ul><h3 id="_3-边缘部署" tabindex="-1"><a class="header-anchor" href="#_3-边缘部署"><span>3. 边缘部署</span></a></h3><ul><li>模型轻量化</li><li>在移动设备上的部署</li></ul><h3 id="_4-可控性和安全性" tabindex="-1"><a class="header-anchor" href="#_4-可控性和安全性"><span>4. 可控性和安全性</span></a></h3><ul><li>更好的内容控制机制</li><li>隐私保护技术</li><li>对齐技术（Alignment）</li></ul><h2 id="大模型实践指南" tabindex="-1"><a class="header-anchor" href="#大模型实践指南"><span>大模型实践指南</span></a></h2><h3 id="_1-模型选择" tabindex="-1"><a class="header-anchor" href="#_1-模型选择"><span>1. 模型选择</span></a></h3><ul><li>根据应用场景选择合适的模型</li><li>考虑计算资源限制</li><li>平衡性能和成本</li></ul><h3 id="_2-微调策略" tabindex="-1"><a class="header-anchor" href="#_2-微调策略"><span>2. 微调策略</span></a></h3><ul><li>准备高质量的训练数据</li><li>选择合适的微调方法</li><li>设置适当的超参数</li></ul><h3 id="_3-部署考虑" tabindex="-1"><a class="header-anchor" href="#_3-部署考虑"><span>3. 部署考虑</span></a></h3><ul><li>选择合适的推理框架（如TensorRT、ONNX等）</li><li>优化推理性能</li><li>设计容错机制</li></ul><p>大模型技术仍在快速发展中，未来有望在更多领域发挥重要作用，同时也需要解决相关的技术和伦理挑战。</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated:: </span><time class="meta-item-info" datetime="2025-12-07T07:07:49.000Z" data-allow-mismatch>12/7/25, 7:07 AM</time></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 1127699551@qq.com">mingwzh</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link route-link-active auto-link prev" href="/llm/" aria-label="大语言模型(LLM)学习笔记"><!--[--><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span class="external-link">大语言模型(LLM)学习笔记</span></div><!--]--></a><a class="route-link auto-link next" href="/llm/transformer-notes.html" aria-label="Transformer架构学习笔记"><!--[--><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span class="external-link">Transformer架构学习笔记</span></div><!--]--></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-BvwJZ6kh.js" defer></script>
  </body>
</html>
