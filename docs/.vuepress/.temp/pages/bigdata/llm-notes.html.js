import comp from "/Users/mingwzh/IdeaProjects/PersonalWiki/docs/.vuepress/.temp/pages/bigdata/llm-notes.html.vue"
const data = JSON.parse("{\"path\":\"/bigdata/llm-notes.html\",\"title\":\"大模型(LLM)学习笔记\",\"lang\":\"en-US\",\"frontmatter\":{},\"headers\":[{\"level\":2,\"title\":\"什么是大模型\",\"slug\":\"什么是大模型\",\"link\":\"#什么是大模型\",\"children\":[]},{\"level\":2,\"title\":\"大模型发展历史\",\"slug\":\"大模型发展历史\",\"link\":\"#大模型发展历史\",\"children\":[{\"level\":3,\"title\":\"1. 早期语言模型\",\"slug\":\"_1-早期语言模型\",\"link\":\"#_1-早期语言模型\",\"children\":[]},{\"level\":3,\"title\":\"2. 预训练模型时代\",\"slug\":\"_2-预训练模型时代\",\"link\":\"#_2-预训练模型时代\",\"children\":[]},{\"level\":3,\"title\":\"3. 大模型爆发期\",\"slug\":\"_3-大模型爆发期\",\"link\":\"#_3-大模型爆发期\",\"children\":[]}]},{\"level\":2,\"title\":\"大模型核心技术\",\"slug\":\"大模型核心技术\",\"link\":\"#大模型核心技术\",\"children\":[{\"level\":3,\"title\":\"1. Transformer架构\",\"slug\":\"_1-transformer架构\",\"link\":\"#_1-transformer架构\",\"children\":[]},{\"level\":3,\"title\":\"2. 预训练与微调\",\"slug\":\"_2-预训练与微调\",\"link\":\"#_2-预训练与微调\",\"children\":[]},{\"level\":3,\"title\":\"3. 扩展定律（Scaling Law）\",\"slug\":\"_3-扩展定律-scaling-law\",\"link\":\"#_3-扩展定律-scaling-law\",\"children\":[]}]},{\"level\":2,\"title\":\"主流大模型介绍\",\"slug\":\"主流大模型介绍\",\"link\":\"#主流大模型介绍\",\"children\":[{\"level\":3,\"title\":\"1. GPT系列（OpenAI）\",\"slug\":\"_1-gpt系列-openai\",\"link\":\"#_1-gpt系列-openai\",\"children\":[]},{\"level\":3,\"title\":\"2. LLaMA系列（Meta）\",\"slug\":\"_2-llama系列-meta\",\"link\":\"#_2-llama系列-meta\",\"children\":[]},{\"level\":3,\"title\":\"3. 其他知名模型\",\"slug\":\"_3-其他知名模型\",\"link\":\"#_3-其他知名模型\",\"children\":[]}]},{\"level\":2,\"title\":\"大模型关键技术\",\"slug\":\"大模型关键技术\",\"link\":\"#大模型关键技术\",\"children\":[{\"level\":3,\"title\":\"1. 微调技术\",\"slug\":\"_1-微调技术\",\"link\":\"#_1-微调技术\",\"children\":[]},{\"level\":3,\"title\":\"2. 模型压缩\",\"slug\":\"_2-模型压缩\",\"link\":\"#_2-模型压缩\",\"children\":[]},{\"level\":3,\"title\":\"3. 推理加速\",\"slug\":\"_3-推理加速\",\"link\":\"#_3-推理加速\",\"children\":[]}]},{\"level\":2,\"title\":\"大模型应用领域\",\"slug\":\"大模型应用领域\",\"link\":\"#大模型应用领域\",\"children\":[{\"level\":3,\"title\":\"1. 自然语言处理\",\"slug\":\"_1-自然语言处理\",\"link\":\"#_1-自然语言处理\",\"children\":[]},{\"level\":3,\"title\":\"2. 代码生成\",\"slug\":\"_2-代码生成\",\"link\":\"#_2-代码生成\",\"children\":[]},{\"level\":3,\"title\":\"3. 多模态应用\",\"slug\":\"_3-多模态应用\",\"link\":\"#_3-多模态应用\",\"children\":[]},{\"level\":3,\"title\":\"4. 专业领域应用\",\"slug\":\"_4-专业领域应用\",\"link\":\"#_4-专业领域应用\",\"children\":[]}]},{\"level\":2,\"title\":\"大模型面临的挑战\",\"slug\":\"大模型面临的挑战\",\"link\":\"#大模型面临的挑战\",\"children\":[{\"level\":3,\"title\":\"1. 技术挑战\",\"slug\":\"_1-技术挑战\",\"link\":\"#_1-技术挑战\",\"children\":[]},{\"level\":3,\"title\":\"2. 伦理与社会挑战\",\"slug\":\"_2-伦理与社会挑战\",\"link\":\"#_2-伦理与社会挑战\",\"children\":[]},{\"level\":3,\"title\":\"3. 安全风险\",\"slug\":\"_3-安全风险\",\"link\":\"#_3-安全风险\",\"children\":[]}]},{\"level\":2,\"title\":\"大模型评估方法\",\"slug\":\"大模型评估方法\",\"link\":\"#大模型评估方法\",\"children\":[{\"level\":3,\"title\":\"1. 基准测试\",\"slug\":\"_1-基准测试\",\"link\":\"#_1-基准测试\",\"children\":[]},{\"level\":3,\"title\":\"2. 人工评估\",\"slug\":\"_2-人工评估\",\"link\":\"#_2-人工评估\",\"children\":[]},{\"level\":3,\"title\":\"3. 特定任务评估\",\"slug\":\"_3-特定任务评估\",\"link\":\"#_3-特定任务评估\",\"children\":[]}]},{\"level\":2,\"title\":\"大模型发展趋势\",\"slug\":\"大模型发展趋势\",\"link\":\"#大模型发展趋势\",\"children\":[{\"level\":3,\"title\":\"1. 模型架构演进\",\"slug\":\"_1-模型架构演进\",\"link\":\"#_1-模型架构演进\",\"children\":[]},{\"level\":3,\"title\":\"2. 多模态融合\",\"slug\":\"_2-多模态融合\",\"link\":\"#_2-多模态融合\",\"children\":[]},{\"level\":3,\"title\":\"3. 边缘部署\",\"slug\":\"_3-边缘部署\",\"link\":\"#_3-边缘部署\",\"children\":[]},{\"level\":3,\"title\":\"4. 可控性和安全性\",\"slug\":\"_4-可控性和安全性\",\"link\":\"#_4-可控性和安全性\",\"children\":[]}]},{\"level\":2,\"title\":\"大模型实践指南\",\"slug\":\"大模型实践指南\",\"link\":\"#大模型实践指南\",\"children\":[{\"level\":3,\"title\":\"1. 模型选择\",\"slug\":\"_1-模型选择\",\"link\":\"#_1-模型选择\",\"children\":[]},{\"level\":3,\"title\":\"2. 微调策略\",\"slug\":\"_2-微调策略\",\"link\":\"#_2-微调策略\",\"children\":[]},{\"level\":3,\"title\":\"3. 部署考虑\",\"slug\":\"_3-部署考虑\",\"link\":\"#_3-部署考虑\",\"children\":[]}]}],\"git\":{},\"filePathRelative\":\"bigdata/llm-notes.md\",\"excerpt\":\"\\n<h2>什么是大模型</h2>\\n<p>大模型（Large Language Model，LLM）是一类具有超大规模参数量的深度学习模型，通常包含数十亿甚至数千亿个参数。它们通过在大量文本数据上进行训练，能够理解和生成人类语言，执行各种自然语言处理任务。</p>\\n<h2>大模型发展历史</h2>\\n<h3>1. 早期语言模型</h3>\\n<ul>\\n<li>N-gram模型：基于统计的语言模型</li>\\n<li>神经网络语言模型：使用神经网络进行语言建模</li>\\n</ul>\\n<h3>2. 预训练模型时代</h3>\\n<ul>\\n<li><strong>2018年：BERT</strong> - Google提出的双向Transformer模型，开启了预训练+微调的新范式</li>\\n<li><strong>2019年：GPT-2</strong> - OpenAI发布的第二代GPT模型，展示了强大的文本生成能力</li>\\n<li><strong>2020年：GPT-3</strong> - OpenAI发布的第一代真正意义上的大模型，拥有1750亿参数</li>\\n</ul>\"}")
export { comp, data }

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updatePageData) {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ data }) => {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  })
}
