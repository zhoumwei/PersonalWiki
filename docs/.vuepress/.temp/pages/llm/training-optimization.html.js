import comp from "/Users/mingwzh/IdeaProjects/PersonalWiki/docs/.vuepress/.temp/pages/llm/training-optimization.html.vue"
const data = JSON.parse("{\"path\":\"/llm/training-optimization.html\",\"title\":\"大模型训练与优化学习笔记\",\"lang\":\"en-US\",\"frontmatter\":{},\"headers\":[{\"level\":2,\"title\":\"大模型训练概述\",\"slug\":\"大模型训练概述\",\"link\":\"#大模型训练概述\",\"children\":[]},{\"level\":2,\"title\":\"大模型训练挑战\",\"slug\":\"大模型训练挑战\",\"link\":\"#大模型训练挑战\",\"children\":[{\"level\":3,\"title\":\"1. 计算资源需求\",\"slug\":\"_1-计算资源需求\",\"link\":\"#_1-计算资源需求\",\"children\":[]},{\"level\":3,\"title\":\"2. 内存瓶颈\",\"slug\":\"_2-内存瓶颈\",\"link\":\"#_2-内存瓶颈\",\"children\":[]},{\"level\":3,\"title\":\"3. 训练稳定性\",\"slug\":\"_3-训练稳定性\",\"link\":\"#_3-训练稳定性\",\"children\":[]}]},{\"level\":2,\"title\":\"训练关键技术\",\"slug\":\"训练关键技术\",\"link\":\"#训练关键技术\",\"children\":[{\"level\":3,\"title\":\"1. 数据并行(Data Parallelism)\",\"slug\":\"_1-数据并行-data-parallelism\",\"link\":\"#_1-数据并行-data-parallelism\",\"children\":[]},{\"level\":3,\"title\":\"2. 模型并行(Model Parallelism)\",\"slug\":\"_2-模型并行-model-parallelism\",\"link\":\"#_2-模型并行-model-parallelism\",\"children\":[]},{\"level\":3,\"title\":\"3. 流水线并行(Pipeline Parallelism)\",\"slug\":\"_3-流水线并行-pipeline-parallelism\",\"link\":\"#_3-流水线并行-pipeline-parallelism\",\"children\":[]},{\"level\":3,\"title\":\"4. 张量并行(Tensor Parallelism)\",\"slug\":\"_4-张量并行-tensor-parallelism\",\"link\":\"#_4-张量并行-tensor-parallelism\",\"children\":[]}]},{\"level\":2,\"title\":\"内存优化技术\",\"slug\":\"内存优化技术\",\"link\":\"#内存优化技术\",\"children\":[{\"level\":3,\"title\":\"1. 梯度检查点(Gradient Checkpointing)\",\"slug\":\"_1-梯度检查点-gradient-checkpointing\",\"link\":\"#_1-梯度检查点-gradient-checkpointing\",\"children\":[]},{\"level\":3,\"title\":\"2. ZeRO优化\",\"slug\":\"_2-zero优化\",\"link\":\"#_2-zero优化\",\"children\":[]},{\"level\":3,\"title\":\"3. 混合精度训练(Mixed Precision Training)\",\"slug\":\"_3-混合精度训练-mixed-precision-training\",\"link\":\"#_3-混合精度训练-mixed-precision-training\",\"children\":[]},{\"level\":3,\"title\":\"4. 卸载技术(Offloading)\",\"slug\":\"_4-卸载技术-offloading\",\"link\":\"#_4-卸载技术-offloading\",\"children\":[]}]},{\"level\":2,\"title\":\"训练优化策略\",\"slug\":\"训练优化策略\",\"link\":\"#训练优化策略\",\"children\":[{\"level\":3,\"title\":\"1. 学习率调度\",\"slug\":\"_1-学习率调度\",\"link\":\"#_1-学习率调度\",\"children\":[]},{\"level\":3,\"title\":\"2. 批量大小优化\",\"slug\":\"_2-批量大小优化\",\"link\":\"#_2-批量大小优化\",\"children\":[]},{\"level\":3,\"title\":\"3. 正则化技术\",\"slug\":\"_3-正则化技术\",\"link\":\"#_3-正则化技术\",\"children\":[]},{\"level\":3,\"title\":\"4. 初始化策略\",\"slug\":\"_4-初始化策略\",\"link\":\"#_4-初始化策略\",\"children\":[]}]},{\"level\":2,\"title\":\"分布式训练框架\",\"slug\":\"分布式训练框架\",\"link\":\"#分布式训练框架\",\"children\":[{\"level\":3,\"title\":\"1. DeepSpeed\",\"slug\":\"_1-deepspeed\",\"link\":\"#_1-deepspeed\",\"children\":[]},{\"level\":3,\"title\":\"2. Megatron-LM\",\"slug\":\"_2-megatron-lm\",\"link\":\"#_2-megatron-lm\",\"children\":[]},{\"level\":3,\"title\":\"3. FairScale\",\"slug\":\"_3-fairscale\",\"link\":\"#_3-fairscale\",\"children\":[]},{\"level\":3,\"title\":\"4. Alpa\",\"slug\":\"_4-alpa\",\"link\":\"#_4-alpa\",\"children\":[]}]},{\"level\":2,\"title\":\"训练监控与调试\",\"slug\":\"训练监控与调试\",\"link\":\"#训练监控与调试\",\"children\":[{\"level\":3,\"title\":\"1. 关键指标监控\",\"slug\":\"_1-关键指标监控\",\"link\":\"#_1-关键指标监控\",\"children\":[]},{\"level\":3,\"title\":\"2. 可视化工具\",\"slug\":\"_2-可视化工具\",\"link\":\"#_2-可视化工具\",\"children\":[]},{\"level\":3,\"title\":\"3. 性能分析\",\"slug\":\"_3-性能分析\",\"link\":\"#_3-性能分析\",\"children\":[]}]},{\"level\":2,\"title\":\"训练技巧与最佳实践\",\"slug\":\"训练技巧与最佳实践\",\"link\":\"#训练技巧与最佳实践\",\"children\":[{\"level\":3,\"title\":\"1. 预训练策略\",\"slug\":\"_1-预训练策略\",\"link\":\"#_1-预训练策略\",\"children\":[]},{\"level\":3,\"title\":\"2. 微调技巧\",\"slug\":\"_2-微调技巧\",\"link\":\"#_2-微调技巧\",\"children\":[]},{\"level\":3,\"title\":\"3. 数据增强\",\"slug\":\"_3-数据增强\",\"link\":\"#_3-数据增强\",\"children\":[]},{\"level\":3,\"title\":\"4. 稳定性保障\",\"slug\":\"_4-稳定性保障\",\"link\":\"#_4-稳定性保障\",\"children\":[]}]},{\"level\":2,\"title\":\"训练成本优化\",\"slug\":\"训练成本优化\",\"link\":\"#训练成本优化\",\"children\":[{\"level\":3,\"title\":\"1. 硬件选择\",\"slug\":\"_1-硬件选择\",\"link\":\"#_1-硬件选择\",\"children\":[]},{\"level\":3,\"title\":\"2. 训练效率优化\",\"slug\":\"_2-训练效率优化\",\"link\":\"#_2-训练效率优化\",\"children\":[]},{\"level\":3,\"title\":\"3. 训练中断恢复\",\"slug\":\"_3-训练中断恢复\",\"link\":\"#_3-训练中断恢复\",\"children\":[]}]},{\"level\":2,\"title\":\"大模型训练未来趋势\",\"slug\":\"大模型训练未来趋势\",\"link\":\"#大模型训练未来趋势\",\"children\":[{\"level\":3,\"title\":\"1. 绿色AI\",\"slug\":\"_1-绿色ai\",\"link\":\"#_1-绿色ai\",\"children\":[]},{\"level\":3,\"title\":\"2. 自动化训练\",\"slug\":\"_2-自动化训练\",\"link\":\"#_2-自动化训练\",\"children\":[]},{\"level\":3,\"title\":\"3. 联邦学习\",\"slug\":\"_3-联邦学习\",\"link\":\"#_3-联邦学习\",\"children\":[]}]}],\"git\":{\"updatedTime\":1765091269000,\"contributors\":[{\"name\":\"mingwzh\",\"username\":\"mingwzh\",\"email\":\"1127699551@qq.com\",\"commits\":1,\"url\":\"https://github.com/mingwzh\"}],\"changelog\":[{\"hash\":\"b058d4bca3374bab5807a7fe00edb3c38db9e19a\",\"time\":1765091269000,\"email\":\"1127699551@qq.com\",\"author\":\"mingwzh\",\"message\":\"docs(llm): 添加大语言模型学习笔记文档\"}]},\"filePathRelative\":\"llm/training-optimization.md\",\"excerpt\":\"\\n<h2>大模型训练概述</h2>\\n<p>大语言模型的训练是一个极其复杂且资源密集的过程，涉及到大量的计算资源、存储资源和时间成本。训练一个高性能的大模型需要深入理解模型架构、训练算法、优化技巧以及分布式计算等多个方面的知识。</p>\\n<h2>大模型训练挑战</h2>\\n<h3>1. 计算资源需求</h3>\\n<ul>\\n<li><strong>巨大的参数量</strong>：现代大模型参数量可达数百亿甚至数千亿</li>\\n<li><strong>庞大的训练数据</strong>：需要TB级别的文本数据进行训练</li>\\n<li><strong>高昂的计算成本</strong>：训练一次可能需要数百万美元的计算资源</li>\\n</ul>\"}")
export { comp, data }

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updatePageData) {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ data }) => {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  })
}
